{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = {\n",
    "    (\"Document1\", \"This is a a a a a a a a aasample\"),\n",
    "    (\"Document2\", \"This is anyr anotheswt\"),\n",
    "    (\"Document3\", \"This is not a sample\")\n",
    "}\n",
    "globalLexicon = dict() #\n",
    "globalDocument = list()\n",
    "globalPosting = list()\n",
    "globalMaxTF = dict()\n",
    "globalTotalTF = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for docName, docContent in collection:\n",
    "    docIdx = len(globalDocument)\n",
    "    globalDocument.append(docName)\n",
    "    #print(globalDocument.index(docName))\n",
    "    \n",
    "    localPostring = dict()\n",
    "    for term in docContent.lower().split() :\n",
    "        if term in localPostring.keys() :\n",
    "            localPostring[term] += 1\n",
    "        else :\n",
    "            localPostring[term] = 1\n",
    "    \n",
    "    globalMaxTF[docIdx] = max(localPostring.values())\n",
    "    globalTotalTF[docIdx] = sum(localPostring.values())\n",
    "\n",
    "    ## local 끝\n",
    "    \n",
    "    for term,freq in localPostring.items() :\n",
    "        if term in globalLexicon.keys():\n",
    "            ## Lexicon term ? =>\n",
    "            #termIdx = list(globalLexicon.keys()).index(term)\n",
    "            postingIdx = len(globalPosting)\n",
    "            globalPosting.append((docIdx, freq, globalLexicon[term]))\n",
    "            globalLexicon[term] = postingIdx\n",
    "        else :\n",
    "            termIdx = len(globalLexicon.keys())\n",
    "            postingIdx = len(globalPosting)\n",
    "            globalLexicon[term] = postingIdx\n",
    "            globalPosting.append((docIdx, freq, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for term, postingIdx in globalLexicon.items() : # TDM.keys()\n",
    "    print(term)\n",
    "    \n",
    "    while True :\n",
    "        if postingIdx == -1 :\n",
    "            break\n",
    "        \n",
    "        print(\" {0} - {1}, {2}, Next={3}\".format(\n",
    "            globalPosting[postingIdx][0],\n",
    "            globalDocument[globalPosting[postingIdx][0]],\n",
    "            globalPosting[postingIdx][1],\n",
    "            globalPosting[postingIdx][2])\n",
    "             )\n",
    "        postingIdx = globalPosting[postingIdx][2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 1, -1), (1, 1, 0), (0, 1, -1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globalLexicon\n",
    "globalPosting[8], globalPosting[4], globalPosting[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TF\n",
    "# 특정 문서 내 특정 단어의 빈도 = f(t,d)\n",
    "# 특정 문서 내 다른 단어의 빈도 => sum, max => DTM(sum,max)\n",
    "from math import log10\n",
    "# log2 < log10\n",
    "\n",
    "def logTF(freq) :\n",
    "    return log10(1+freq)\n",
    "\n",
    "def totalTF(freq, totalFreq) :\n",
    "    return freq/totalFreq\n",
    "\n",
    "# alpha = 0[0-1] , query = 0.5[0.5-1]\n",
    "def doubleTF(freq, maxFreq, alpha = 0.5) :\n",
    "    return alpha + (1-alpha)*(freq/MaxFreq)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IDF\n",
    "# 전체 문서의 갯수 => N\n",
    "# 특정 단어가 나타난 문서의 갯수 => df(t) => \n",
    "\n",
    "# is a the of => stopwords ==> 0 \n",
    "# to be or not to be = 0\n",
    "def idf(df,N) :\n",
    "    return log10(N/df)\n",
    "\n",
    "#  0 이상 나옴\n",
    "def smoothingIdf(df, N) :\n",
    "    return log10(N/1+df)\n",
    "\n",
    "# 특정기준값을 바탕으로 부호가 바뀜\n",
    "def probabilisticIdf(df, N) :\n",
    "    return log10((N-df+1)/df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 : 포스팅 위치\n",
    "# while -1 : 어떤 문서의 인덱스: 빈도: 다음 문서의 위치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TF-IDF\n",
    "N = len(globalDocument)\n",
    "\n",
    "for term, postingIdx in globalLexicon.items() : # TDM.keys()\n",
    "    old = postingIdx\n",
    "    df = 0 \n",
    "    \n",
    "    while True :\n",
    "        if postingIdx == -1 :\n",
    "            break\n",
    "        df += 1\n",
    "    \n",
    "    postingIdx = old\n",
    "    idf1 = idf(df, N)\n",
    "    idf2 = smoothingIdf(df,N)\n",
    "    idf3 = probabilisticIdf(df,N)\n",
    "        \n",
    "    while True :\n",
    "        if postingIdx == -1 :\n",
    "            break\n",
    "        \n",
    "        data = globalPosting[postingIdx]\n",
    "        postingIdx = data[2]\n",
    "        tf = doubleTF(data[1], globalMaxTF[data[0]])\n",
    "        print(\"{0}-{1}\".format(term, globalDocument[data[0]]))\n",
    "        print(\" => {0} * {1} = {2}\".format(tf,idf1,tf*idf1))\n",
    "        print(\" => {0} * {1} = {2}\".format(tf,idf1,tf*idf2))\n",
    "        print(\" => {0} * {1} = {2}\".format(tf,idf1,tf*idf3))\n",
    "        #print(\"{0} - DocIdx:{1}, TF:{2}, Max:{3}, Total:{4}\".format(\n",
    "        #    term, data[0], data[1], globalMaxTF[data[0]], globalTotalTF[data[0]]\n",
    "        #))\n",
    "        #print(\" TF1:{0}\".format(logTF(data[1])))\n",
    "        #print(\" TF2:{0}\".format(totalTF(data[1])))\n",
    "        #print(\" TF2:{0}\".format(doubleTF(data[1])))\n",
    "    print()\n",
    "        \n",
    "    #print(\" {0} -  DF :{1}, N:{2}\".format(term,df,N))\n",
    "    #print(\" IDF1:{0}\".format(idf(df,N)))\n",
    "    #print(\" IDF2:{0}\".format(smoothingIdf(df,N)))\n",
    "    #print(\" IDF3:{0}\".format(probabilisticIdf(df,N)))\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
