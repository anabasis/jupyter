{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'd like to learn more something.\""
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://programmers.co.kr/learn/courses/21/lessons/1694\n",
    "\n",
    "import re\n",
    "from string import punctuation\n",
    "\n",
    "# Normalization\n",
    "# 1. 대소문자 통합(소문자)\n",
    "# 2. 구두점 처리(I'd, I'm) ==> tokenizing\n",
    "#     => 대안 : 형태소 분섟\n",
    "# 3. 불용어(stopwards) 처리\n",
    "\n",
    "sentence = \"I'd like to learn more something.\"\n",
    "\n",
    "pattern = re.compile(\"[{0}]\".format(re.escape(punctuation)))\n",
    "#print(pattern = re.compile(\" \",sentence.lower()))\n",
    "#print(pattern = (\"\".join(word_tokenize(sentence.lower()))))\n",
    "\n",
    "#sentence.lower()\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Id like to learn more something'"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from string import punctuation\n",
    "\n",
    "punctuation\n",
    "# '오늘'의 ==> 오늘 의, 오늘의\n",
    "\n",
    "#re.sub(\"[{0}]\").format(re.escape(punctuation)),\"\",sentence)\n",
    "re.sub(\"[{0}]\".format(re.escape(punctuation)),\"\",sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('book', quiet=True)\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download(\"stopwords\")\n",
    "# Stopwords\n",
    "#nltk.download('brown')\n",
    "#nltk.download('gutenberg')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords.fileids()\n",
    "stop = stopwords.open(\"english\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "me\n",
      "my\n",
      "myself\n",
      "we\n",
      "our\n",
      "ours\n",
      "ourselves\n",
      "you\n",
      "you're\n",
      "you've\n",
      "you'll\n",
      "you'd\n",
      "your\n",
      "yours\n",
      "yourself\n",
      "yourselves\n",
      "he\n",
      "him\n",
      "his\n",
      "himself\n",
      "she\n",
      "she's\n",
      "her\n",
      "hers\n",
      "herself\n",
      "it\n",
      "it's\n",
      "its\n",
      "itself\n",
      "they\n",
      "them\n",
      "their\n",
      "theirs\n",
      "themselves\n",
      "what\n",
      "which\n",
      "who\n",
      "whom\n",
      "this\n",
      "that\n",
      "that'll\n",
      "these\n",
      "those\n",
      "am\n",
      "is\n",
      "are\n",
      "was\n",
      "were\n",
      "be\n",
      "been\n",
      "being\n",
      "have\n",
      "has\n",
      "had\n",
      "having\n",
      "do\n",
      "does\n",
      "did\n",
      "doing\n",
      "a\n",
      "an\n",
      "the\n",
      "and\n",
      "but\n",
      "if\n",
      "or\n",
      "because\n",
      "as\n",
      "until\n",
      "while\n",
      "of\n",
      "at\n",
      "by\n",
      "for\n",
      "with\n",
      "about\n",
      "against\n",
      "between\n",
      "into\n",
      "through\n",
      "during\n",
      "before\n",
      "after\n",
      "above\n",
      "below\n",
      "to\n",
      "from\n",
      "up\n",
      "down\n",
      "in\n",
      "out\n",
      "on\n",
      "off\n",
      "over\n",
      "under\n",
      "again\n",
      "further\n",
      "then\n",
      "once\n",
      "here\n",
      "there\n",
      "when\n",
      "where\n",
      "why\n",
      "how\n",
      "all\n",
      "any\n",
      "both\n",
      "each\n",
      "few\n",
      "more\n",
      "most\n",
      "other\n",
      "some\n",
      "such\n",
      "no\n",
      "nor\n",
      "not\n",
      "only\n",
      "own\n",
      "same\n",
      "so\n",
      "than\n",
      "too\n",
      "very\n",
      "s\n",
      "t\n",
      "can\n",
      "will\n",
      "just\n",
      "don\n",
      "don't\n",
      "should\n",
      "should've\n",
      "now\n",
      "d\n",
      "ll\n",
      "m\n",
      "o\n",
      "re\n",
      "ve\n",
      "y\n",
      "ain\n",
      "aren\n",
      "aren't\n",
      "couldn\n",
      "couldn't\n",
      "didn\n",
      "didn't\n",
      "doesn\n",
      "doesn't\n",
      "hadn\n",
      "hadn't\n",
      "hasn\n",
      "hasn't\n",
      "haven\n",
      "haven't\n",
      "isn\n",
      "isn't\n",
      "ma\n",
      "mightn\n",
      "mightn't\n",
      "mustn\n",
      "mustn't\n",
      "needn\n",
      "needn't\n",
      "shan\n",
      "shan't\n",
      "shouldn\n",
      "shouldn't\n",
      "wasn\n",
      "wasn't\n",
      "weren\n",
      "weren't\n",
      "won\n",
      "won't\n",
      "wouldn\n",
      "wouldn't\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(936, None)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop), print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beautiful\n",
      "Skipped\n",
      "better\n",
      "Skipped\n",
      "ugly\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I love you\"\n",
    "sentence = \"Beautiful is better than ugly\"\n",
    "\n",
    "for _ in word_tokenize(sentence.lower()):  # 1번\n",
    "    if pattern.sub(\"\",_) in stop :  # 2번\n",
    "#for _ in pattern.sub(\"\", sentence.lower()).split() :\n",
    "#    if _ in stop :\n",
    "        print(\"Skipped\")\n",
    "    else :\n",
    "        print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69791"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "corpus = gutenberg.open('austen-emma.txt').read()\n",
    "\n",
    "len(word_tokenize(corpus))  # 19만개 -> 6.9만개\n",
    "words = list()\n",
    "\n",
    "for _ in word_tokenize(corpus.lower()): # 1번\n",
    "    if pattern.sub(\"\",_) not in stop :  # 2번 with stopwords\n",
    "        words.append(_)\n",
    "        \n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, ['어머니', '짜장면', '싫다', '하셨'])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "korstop = [\"은\",\"는\",\"이\",\"가\",\"을\",\"를\",\"께서\",\"에게\",\"고\",\"어\"]\n",
    "sentence = \"어머니 는 짜장면 이 싫다 고 하셨 어.\"\n",
    "sentence = pattern.sub(\"\", sentence)\n",
    "\n",
    "len(word_tokenize(sentence)), word_tokenize(sentence)\n",
    "\n",
    "len([ _ for _ in word_tokenize(sentence) if _ not in korstop]), [ _ for _ in word_tokenize(sentence) if _ not in korstop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like\n",
      "learn\n",
      "more\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['like', 'to', 'learn', 'more']"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I'd like to learn more something.\"\n",
    "#sentence = \"어머니 는 짜장면 이 싫다 고 하셨 어.\"\n",
    "# 길이 정규화 => 특정길이(너무짧거나 너무 길거나)\n",
    "for _ in pattern.sub(\"\", sentence.lower()).split() :\n",
    "    if 2 < len(_) < 6 :\n",
    "        print(_)\n",
    "\n",
    "# 길이로 정규화\n",
    "minimum = 2\n",
    "maximum = 6\n",
    "pattern2 = re.compile(r\"\\b\\w{%d,%d}\\b\" % (minimum, maximum))\n",
    "pattern2.findall(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like 2\n",
      "to 2\n",
      "learn 2\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I'd like to learn more something. like to learn \"\n",
    "#sentence = \"어머니 는 짜장면 이 싫다 고 하셨 어.\n",
    "\n",
    "# 빈도로 정규화\n",
    "obj = Text(word_tokenize(sentence.lower()))\n",
    "for _ in obj.vocab() :\n",
    "    if 1 < obj.vocab().get(_) < 3 :\n",
    "        print(_, obj.vocab().get(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191785 8406\n",
      "191781 7944\n",
      "158270 9311\n",
      "162122 7102\n",
      "70168 6933\n",
      "63814 6763\n",
      "48961 1111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([(',', 12016),\n",
       "  ('.', 6355),\n",
       "  ('to', 5125),\n",
       "  ('the', 4844),\n",
       "  ('and', 4653),\n",
       "  ('of', 4272),\n",
       "  ('I', 3177),\n",
       "  ('--', 3100),\n",
       "  ('a', 3001),\n",
       "  (\"''\", 2452)],\n",
       " [('mr', 1154),\n",
       "  ('emma', 865),\n",
       "  ('mrs', 701),\n",
       "  ('miss', 602),\n",
       "  ('harriet', 506),\n",
       "  ('much', 486),\n",
       "  ('said', 484),\n",
       "  ('one', 458),\n",
       "  ('weston', 440),\n",
       "  ('every', 435)])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords.fileids()\n",
    "stop = stopwords.open(\"english\").read()\n",
    "#print(stop)\n",
    "\n",
    "original = Text(word_tokenize(corpus))\n",
    "print(original.vocab().N(),original.vocab().B())\n",
    "#original.vocab().most_common(50)\n",
    "\n",
    "lowercase = Text(word_tokenize(corpus.lower()))\n",
    "print( lowercase.vocab().N() , lowercase.vocab().B())\n",
    "\n",
    "punct1 = Text(word_tokenize(pattern.sub(\"\" , corpus.lower())))\n",
    "print( punct1.vocab().N() , punct1.vocab().B())\n",
    "\n",
    "punct2 = Text(word_tokenize(pattern.sub(\" \" , corpus.lower())))\n",
    "print( punct2.vocab().N() , punct2.vocab().B())\n",
    "\n",
    "stops = Text([ _ for _ in word_tokenize(pattern.sub(\" \",corpus.lower())) if _ not in stop])\n",
    "print( stops.vocab().N() , stops.vocab().B())\n",
    "\n",
    "# 글자 길이 > 3\n",
    "# 빈도 < 10\n",
    "length = Text([ _ for _ in word_tokenize(pattern.sub(\" \",corpus.lower())) if _ not in stop and re.search(r\"\\b\\w{4,}\\b\",_)])\n",
    "print( length.vocab().N() , length.vocab().B())\n",
    "\n",
    "#freq = [ _ for _ in length.vocab()  if length.vocab().get(_) > 10]\n",
    "#print(len(freq))\n",
    "freq = [(_,length.count(_)) for _ in length.vocab() if length.vocab().get(_) > 10]\n",
    "print(sum([_[1] for _ in freq]), len(freq))\n",
    "\n",
    "original.vocab().most_common(10), stops.vocab().most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100461,\n",
       " ['[',\n",
       "  'emma',\n",
       "  'jane',\n",
       "  'austen',\n",
       "  '1816',\n",
       "  ']',\n",
       "  'volume',\n",
       "  'chapter',\n",
       "  'emma',\n",
       "  'woodhouse',\n",
       "  ',',\n",
       "  'handsome',\n",
       "  ',',\n",
       "  'clever',\n",
       "  ',',\n",
       "  'rich',\n",
       "  ',',\n",
       "  'comfortable',\n",
       "  'home',\n",
       "  'happy',\n",
       "  'disposition',\n",
       "  ',',\n",
       "  'seemed',\n",
       "  'unite',\n",
       "  'best',\n",
       "  'blessings',\n",
       "  'existence',\n",
       "  ';',\n",
       "  'lived',\n",
       "  'nearly',\n",
       "  'twenty-one',\n",
       "  'years',\n",
       "  'world',\n",
       "  'little',\n",
       "  'distress',\n",
       "  'vex',\n",
       "  '.',\n",
       "  'youngest',\n",
       "  'two',\n",
       "  'daughters',\n",
       "  'affectionate',\n",
       "  ',',\n",
       "  'indulgent',\n",
       "  'father',\n",
       "  ';',\n",
       "  ',',\n",
       "  'consequence',\n",
       "  'sister',\n",
       "  'marriage',\n",
       "  ',',\n",
       "  'mistress',\n",
       "  'house',\n",
       "  'early',\n",
       "  'period',\n",
       "  '.',\n",
       "  'mother',\n",
       "  'died',\n",
       "  'long',\n",
       "  'ago',\n",
       "  'indistinct',\n",
       "  'remembrance',\n",
       "  'caresses',\n",
       "  ';',\n",
       "  'place',\n",
       "  'supplied',\n",
       "  'excellent',\n",
       "  'woman',\n",
       "  'governess',\n",
       "  ',',\n",
       "  'fallen',\n",
       "  'little',\n",
       "  'short',\n",
       "  'mother',\n",
       "  'affection',\n",
       "  '.',\n",
       "  'sixteen',\n",
       "  'years',\n",
       "  'miss',\n",
       "  'taylor',\n",
       "  'mr.',\n",
       "  'woodhouse',\n",
       "  'family',\n",
       "  ',',\n",
       "  'less',\n",
       "  'governess',\n",
       "  'friend',\n",
       "  ',',\n",
       "  'fond',\n",
       "  'daughters',\n",
       "  ',',\n",
       "  'particularly',\n",
       "  'emma',\n",
       "  '.',\n",
       "  '_them_',\n",
       "  'intimacy',\n",
       "  'sisters',\n",
       "  '.',\n",
       "  'even',\n",
       "  'miss',\n",
       "  'taylor',\n",
       "  'ceased',\n",
       "  'hold',\n",
       "  'nominal',\n",
       "  'office',\n",
       "  'governess',\n",
       "  ',',\n",
       "  'mildness',\n",
       "  'temper',\n",
       "  'hardly',\n",
       "  'allowed',\n",
       "  'impose',\n",
       "  'restraint',\n",
       "  ';',\n",
       "  'shadow',\n",
       "  'authority',\n",
       "  'long',\n",
       "  'passed',\n",
       "  'away',\n",
       "  ',',\n",
       "  'living',\n",
       "  'together',\n",
       "  'friend',\n",
       "  'friend',\n",
       "  'mutually',\n",
       "  'attached',\n",
       "  ',',\n",
       "  'emma',\n",
       "  'liked',\n",
       "  ';',\n",
       "  'highly',\n",
       "  'esteeming',\n",
       "  'miss',\n",
       "  'taylor',\n",
       "  'judgment',\n",
       "  ',',\n",
       "  'directed',\n",
       "  'chiefly',\n",
       "  '.',\n",
       "  'real',\n",
       "  'evils',\n",
       "  ',',\n",
       "  'indeed',\n",
       "  ',',\n",
       "  'emma',\n",
       "  'situation',\n",
       "  'power',\n",
       "  'rather',\n",
       "  'much',\n",
       "  'way',\n",
       "  ',',\n",
       "  'disposition',\n",
       "  'think',\n",
       "  'little',\n",
       "  'well',\n",
       "  ';',\n",
       "  'disadvantages',\n",
       "  'threatened',\n",
       "  'alloy',\n",
       "  'many',\n",
       "  'enjoyments',\n",
       "  '.',\n",
       "  'danger',\n",
       "  ',',\n",
       "  'however',\n",
       "  ',',\n",
       "  'present',\n",
       "  'unperceived',\n",
       "  ',',\n",
       "  'means',\n",
       "  'rank',\n",
       "  'misfortunes',\n",
       "  '.',\n",
       "  'sorrow',\n",
       "  'came',\n",
       "  '--',\n",
       "  'gentle',\n",
       "  'sorrow',\n",
       "  '--',\n",
       "  'shape',\n",
       "  'disagreeable',\n",
       "  'consciousness.',\n",
       "  '--',\n",
       "  'miss',\n",
       "  'taylor',\n",
       "  'married',\n",
       "  '.',\n",
       "  'miss',\n",
       "  'taylor',\n",
       "  'loss',\n",
       "  'first',\n",
       "  'brought',\n",
       "  'grief',\n",
       "  '.',\n",
       "  'wedding-day',\n",
       "  'beloved',\n",
       "  'friend',\n",
       "  'emma',\n",
       "  'first',\n",
       "  'sat',\n",
       "  'mournful',\n",
       "  'thought',\n",
       "  'continuance',\n",
       "  '.',\n",
       "  'wedding',\n",
       "  ',',\n",
       "  'bride-people',\n",
       "  'gone',\n",
       "  ',',\n",
       "  'father',\n",
       "  'left',\n",
       "  'dine',\n",
       "  'together',\n",
       "  ',',\n",
       "  'prospect',\n",
       "  'third',\n",
       "  'cheer',\n",
       "  'long',\n",
       "  'evening',\n",
       "  '.',\n",
       "  'father',\n",
       "  'composed',\n",
       "  'sleep',\n",
       "  'dinner',\n",
       "  ',',\n",
       "  'usual',\n",
       "  ',',\n",
       "  'sit',\n",
       "  'think',\n",
       "  'lost',\n",
       "  '.',\n",
       "  'event',\n",
       "  'every',\n",
       "  'promise',\n",
       "  'happiness',\n",
       "  'friend',\n",
       "  '.',\n",
       "  'mr.',\n",
       "  'weston',\n",
       "  'man',\n",
       "  'unexceptionable',\n",
       "  'character',\n",
       "  ',',\n",
       "  'easy',\n",
       "  'fortune',\n",
       "  ',',\n",
       "  'suitable',\n",
       "  'age',\n",
       "  ',',\n",
       "  'pleasant',\n",
       "  'manners',\n",
       "  ';',\n",
       "  'satisfaction',\n",
       "  'considering',\n",
       "  'self-denying',\n",
       "  ',',\n",
       "  'generous',\n",
       "  'friendship',\n",
       "  'always',\n",
       "  'wished',\n",
       "  'promoted',\n",
       "  'match',\n",
       "  ';',\n",
       "  'black',\n",
       "  'morning',\n",
       "  'work',\n",
       "  '.',\n",
       "  'want',\n",
       "  'miss',\n",
       "  'taylor',\n",
       "  'felt',\n",
       "  'every',\n",
       "  'hour',\n",
       "  'every',\n",
       "  'day',\n",
       "  '.',\n",
       "  'recalled',\n",
       "  'past',\n",
       "  'kindness',\n",
       "  '--',\n",
       "  'kindness',\n",
       "  ',',\n",
       "  'affection',\n",
       "  'sixteen',\n",
       "  'years',\n",
       "  '--',\n",
       "  'taught',\n",
       "  'played',\n",
       "  'five',\n",
       "  'years',\n",
       "  'old',\n",
       "  '--',\n",
       "  'devoted',\n",
       "  'powers',\n",
       "  'attach',\n",
       "  'amuse',\n",
       "  'health',\n",
       "  '--',\n",
       "  'nursed',\n",
       "  'various',\n",
       "  'illnesses',\n",
       "  'childhood',\n",
       "  '.',\n",
       "  'large',\n",
       "  'debt',\n",
       "  'gratitude',\n",
       "  'owing',\n",
       "  ';',\n",
       "  'intercourse',\n",
       "  'last',\n",
       "  'seven',\n",
       "  'years',\n",
       "  ',',\n",
       "  'equal',\n",
       "  'footing',\n",
       "  'perfect',\n",
       "  'unreserve',\n",
       "  'soon',\n",
       "  'followed',\n",
       "  'isabella',\n",
       "  'marriage',\n",
       "  ',',\n",
       "  'left',\n",
       "  ',',\n",
       "  'yet',\n",
       "  'dearer',\n",
       "  ',',\n",
       "  'tenderer',\n",
       "  'recollection',\n",
       "  '.',\n",
       "  'friend',\n",
       "  'companion',\n",
       "  'possessed',\n",
       "  ':',\n",
       "  'intelligent',\n",
       "  ',',\n",
       "  'well-informed',\n",
       "  ',',\n",
       "  'useful',\n",
       "  ',',\n",
       "  'gentle',\n",
       "  ',',\n",
       "  'knowing',\n",
       "  'ways',\n",
       "  'family',\n",
       "  ',',\n",
       "  'interested',\n",
       "  'concerns',\n",
       "  ',',\n",
       "  'peculiarly',\n",
       "  'interested',\n",
       "  ',',\n",
       "  'every',\n",
       "  'pleasure',\n",
       "  ',',\n",
       "  'every',\n",
       "  'scheme',\n",
       "  '--',\n",
       "  'one',\n",
       "  'speak',\n",
       "  'every',\n",
       "  'thought',\n",
       "  'arose',\n",
       "  ',',\n",
       "  'affection',\n",
       "  'never',\n",
       "  'find',\n",
       "  'fault',\n",
       "  '.',\n",
       "  'bear',\n",
       "  'change',\n",
       "  '?',\n",
       "  '--',\n",
       "  'true',\n",
       "  'friend',\n",
       "  'going',\n",
       "  'half',\n",
       "  'mile',\n",
       "  ';',\n",
       "  'emma',\n",
       "  'aware',\n",
       "  'great',\n",
       "  'difference',\n",
       "  'mrs.',\n",
       "  'weston',\n",
       "  ',',\n",
       "  'half',\n",
       "  'mile',\n",
       "  ',',\n",
       "  'miss',\n",
       "  'taylor',\n",
       "  'house',\n",
       "  ';',\n",
       "  'advantages',\n",
       "  ',',\n",
       "  'natural',\n",
       "  'domestic',\n",
       "  ',',\n",
       "  'great',\n",
       "  'danger',\n",
       "  'suffering',\n",
       "  'intellectual',\n",
       "  'solitude',\n",
       "  '.',\n",
       "  'dearly',\n",
       "  'loved',\n",
       "  'father',\n",
       "  ',',\n",
       "  'companion',\n",
       "  '.',\n",
       "  'meet',\n",
       "  'conversation',\n",
       "  ',',\n",
       "  'rational',\n",
       "  'playful',\n",
       "  '.',\n",
       "  'evil',\n",
       "  'actual',\n",
       "  'disparity',\n",
       "  'ages',\n",
       "  '(',\n",
       "  'mr.',\n",
       "  'woodhouse',\n",
       "  'married',\n",
       "  'early',\n",
       "  ')',\n",
       "  'much',\n",
       "  'increased',\n",
       "  'constitution',\n",
       "  'habits',\n",
       "  ';',\n",
       "  'valetudinarian',\n",
       "  'life',\n",
       "  ',',\n",
       "  'without',\n",
       "  'activity',\n",
       "  'mind',\n",
       "  'body',\n",
       "  ',',\n",
       "  'much',\n",
       "  'older',\n",
       "  'man',\n",
       "  'ways',\n",
       "  'years',\n",
       "  ';',\n",
       "  'though',\n",
       "  'everywhere',\n",
       "  'beloved',\n",
       "  'friendliness',\n",
       "  'heart',\n",
       "  'amiable',\n",
       "  'temper',\n",
       "  ',',\n",
       "  'talents',\n",
       "  'recommended',\n",
       "  'time',\n",
       "  '.',\n",
       "  'sister',\n",
       "  ',',\n",
       "  'though',\n",
       "  'comparatively',\n",
       "  'little',\n",
       "  'removed',\n",
       "  'matrimony',\n",
       "  ',',\n",
       "  'settled',\n",
       "  'london',\n",
       "  ',',\n",
       "  'sixteen',\n",
       "  'miles',\n",
       "  ',',\n",
       "  'much',\n",
       "  'beyond',\n",
       "  'daily',\n",
       "  'reach',\n",
       "  ';',\n",
       "  'many',\n",
       "  'long',\n",
       "  'october',\n",
       "  'november',\n",
       "  'evening',\n",
       "  'struggled',\n",
       "  'hartfield',\n",
       "  ',',\n",
       "  'christmas',\n",
       "  'brought',\n",
       "  'next',\n",
       "  'visit',\n",
       "  'isabella',\n",
       "  'husband',\n",
       "  ',',\n",
       "  'little',\n",
       "  'children',\n",
       "  ',',\n",
       "  'fill',\n",
       "  'house',\n",
       "  ',',\n",
       "  'give',\n",
       "  'pleasant',\n",
       "  'society',\n",
       "  '.',\n",
       "  'highbury',\n",
       "  ',',\n",
       "  'large',\n",
       "  'populous',\n",
       "  'village',\n",
       "  ',',\n",
       "  'almost',\n",
       "  'amounting',\n",
       "  'town',\n",
       "  ',',\n",
       "  'hartfield',\n",
       "  ',',\n",
       "  'spite',\n",
       "  'separate',\n",
       "  'lawn',\n",
       "  ',',\n",
       "  'shrubberies',\n",
       "  ',',\n",
       "  'name',\n",
       "  ',',\n",
       "  'really',\n",
       "  'belong',\n",
       "  ',',\n",
       "  'afforded',\n",
       "  'equals',\n",
       "  '.',\n",
       "  'woodhouses',\n",
       "  'first',\n",
       "  'consequence',\n",
       "  '.',\n",
       "  'looked',\n",
       "  '.',\n",
       "  'many',\n",
       "  'acquaintance',\n",
       "  'place',\n",
       "  ',',\n",
       "  'father',\n",
       "  'universally',\n",
       "  'civil',\n",
       "  ',',\n",
       "  'one',\n",
       "  'among',\n",
       "  'accepted',\n",
       "  'lieu',\n",
       "  'miss',\n",
       "  'taylor',\n",
       "  'even',\n",
       "  'half',\n",
       "  'day',\n",
       "  '.',\n",
       "  'melancholy',\n",
       "  'change',\n",
       "  ';',\n",
       "  'emma',\n",
       "  'sigh',\n",
       "  ',',\n",
       "  'wish',\n",
       "  'impossible',\n",
       "  'things',\n",
       "  ',',\n",
       "  'till',\n",
       "  'father',\n",
       "  'awoke',\n",
       "  ',',\n",
       "  'made',\n",
       "  'necessary',\n",
       "  'cheerful',\n",
       "  '.',\n",
       "  'spirits',\n",
       "  'required',\n",
       "  'support',\n",
       "  '.',\n",
       "  'nervous',\n",
       "  'man',\n",
       "  ',',\n",
       "  'easily',\n",
       "  'depressed',\n",
       "  ';',\n",
       "  'fond',\n",
       "  'every',\n",
       "  'body',\n",
       "  'used',\n",
       "  ',',\n",
       "  'hating',\n",
       "  'part',\n",
       "  ';',\n",
       "  'hating',\n",
       "  'change',\n",
       "  'every',\n",
       "  'kind',\n",
       "  '.',\n",
       "  'matrimony',\n",
       "  ',',\n",
       "  'origin',\n",
       "  'change',\n",
       "  ',',\n",
       "  'always',\n",
       "  'disagreeable',\n",
       "  ';',\n",
       "  'means',\n",
       "  'yet',\n",
       "  'reconciled',\n",
       "  'daughter',\n",
       "  'marrying',\n",
       "  ',',\n",
       "  'ever',\n",
       "  'speak',\n",
       "  'compassion',\n",
       "  ',',\n",
       "  'though',\n",
       "  'entirely',\n",
       "  'match',\n",
       "  'affection',\n",
       "  ',',\n",
       "  'obliged',\n",
       "  'part',\n",
       "  'miss',\n",
       "  'taylor',\n",
       "  ';',\n",
       "  'habits',\n",
       "  'gentle',\n",
       "  'selfishness',\n",
       "  ',',\n",
       "  'never',\n",
       "  'able',\n",
       "  'suppose',\n",
       "  'people',\n",
       "  'feel',\n",
       "  'differently',\n",
       "  ',',\n",
       "  'much',\n",
       "  'disposed',\n",
       "  'think',\n",
       "  'miss',\n",
       "  'taylor',\n",
       "  'done',\n",
       "  'sad',\n",
       "  'thing',\n",
       "  ',',\n",
       "  'great',\n",
       "  'deal',\n",
       "  'happier',\n",
       "  'spent',\n",
       "  'rest',\n",
       "  'life',\n",
       "  'hartfield',\n",
       "  '.',\n",
       "  'emma',\n",
       "  'smiled',\n",
       "  'chatted',\n",
       "  'cheerfully',\n",
       "  ',',\n",
       "  'keep',\n",
       "  'thoughts',\n",
       "  ';',\n",
       "  'tea',\n",
       "  'came',\n",
       "  ',',\n",
       "  'impossible',\n",
       "  'say',\n",
       "  'exactly',\n",
       "  'said',\n",
       "  'dinner',\n",
       "  ',',\n",
       "  \"''\",\n",
       "  'poor',\n",
       "  'miss',\n",
       "  'taylor',\n",
       "  '!',\n",
       "  '--',\n",
       "  'wish',\n",
       "  '.',\n",
       "  'pity',\n",
       "  'mr.',\n",
       "  'weston',\n",
       "  'ever',\n",
       "  'thought',\n",
       "  '!',\n",
       "  \"''\",\n",
       "  '``',\n",
       "  'agree',\n",
       "  ',',\n",
       "  'papa',\n",
       "  ';',\n",
       "  'know',\n",
       "  '.',\n",
       "  'mr.',\n",
       "  'weston',\n",
       "  'good-humoured',\n",
       "  ',',\n",
       "  'pleasant',\n",
       "  ',',\n",
       "  'excellent',\n",
       "  'man',\n",
       "  ',',\n",
       "  'thoroughly',\n",
       "  'deserves',\n",
       "  'good',\n",
       "  'wife',\n",
       "  ';',\n",
       "  '--',\n",
       "  'miss',\n",
       "  'taylor',\n",
       "  'live',\n",
       "  'ever',\n",
       "  ',',\n",
       "  'bear',\n",
       "  'odd',\n",
       "  'humours',\n",
       "  ',',\n",
       "  'house',\n",
       "  '?',\n",
       "  \"''\",\n",
       "  '``',\n",
       "  'house',\n",
       "  '!',\n",
       "  '--',\n",
       "  'advantage',\n",
       "  'house',\n",
       "  '?',\n",
       "  'three',\n",
       "  'times',\n",
       "  'large.',\n",
       "  '--',\n",
       "  'never',\n",
       "  'odd',\n",
       "  'humours',\n",
       "  ',',\n",
       "  'dear',\n",
       "  '.',\n",
       "  \"''\",\n",
       "  '``',\n",
       "  'often',\n",
       "  'shall',\n",
       "  'going',\n",
       "  'see',\n",
       "  ',',\n",
       "  'coming',\n",
       "  'see',\n",
       "  '!',\n",
       "  '--',\n",
       "  'shall',\n",
       "  'always',\n",
       "  'meeting',\n",
       "  '!',\n",
       "  '_we_',\n",
       "  'begin',\n",
       "  ';',\n",
       "  'go',\n",
       "  'pay',\n",
       "  'wedding',\n",
       "  'visit',\n",
       "  'soon',\n",
       "  '.',\n",
       "  \"''\",\n",
       "  '``',\n",
       "  'dear',\n",
       "  ',',\n",
       "  'get',\n",
       "  'far',\n",
       "  '?',\n",
       "  'randalls',\n",
       "  'distance',\n",
       "  '.',\n",
       "  'walk',\n",
       "  'half',\n",
       "  'far',\n",
       "  '.',\n",
       "  \"''\",\n",
       "  '``',\n",
       "  ',',\n",
       "  'papa',\n",
       "  ',',\n",
       "  'nobody',\n",
       "  'thought',\n",
       "  'walking',\n",
       "  '.',\n",
       "  'go',\n",
       "  'carriage',\n",
       "  ',',\n",
       "  'sure',\n",
       "  '.',\n",
       "  \"''\",\n",
       "  '``',\n",
       "  'carriage',\n",
       "  '!',\n",
       "  'james',\n",
       "  'like',\n",
       "  'put',\n",
       "  'horses',\n",
       "  'little',\n",
       "  'way',\n",
       "  ';',\n",
       "  '--',\n",
       "  'poor',\n",
       "  'horses',\n",
       "  'paying',\n",
       "  'visit',\n",
       "  '?',\n",
       "  \"''\",\n",
       "  '``',\n",
       "  'put',\n",
       "  'mr.',\n",
       "  'weston',\n",
       "  'stable',\n",
       "  ',',\n",
       "  'papa',\n",
       "  '.',\n",
       "  'know',\n",
       "  'settled',\n",
       "  'already',\n",
       "  '.',\n",
       "  'talked',\n",
       "  'mr.',\n",
       "  'weston',\n",
       "  'last',\n",
       "  'night',\n",
       "  '.',\n",
       "  'james',\n",
       "  ',',\n",
       "  'may',\n",
       "  'sure',\n",
       "  'always',\n",
       "  'like',\n",
       "  'going',\n",
       "  'randalls',\n",
       "  ',',\n",
       "  'daughter',\n",
       "  'housemaid',\n",
       "  '.',\n",
       "  'doubt',\n",
       "  'whether',\n",
       "  'ever',\n",
       "  'take',\n",
       "  'anywhere',\n",
       "  'else',\n",
       "  '.',\n",
       "  ',',\n",
       "  'papa',\n",
       "  '.',\n",
       "  'got',\n",
       "  'hannah',\n",
       "  'good',\n",
       "  'place',\n",
       "  '.',\n",
       "  'nobody',\n",
       "  'thought',\n",
       "  'hannah',\n",
       "  'till',\n",
       "  'mentioned',\n",
       "  '--',\n",
       "  'james',\n",
       "  'obliged',\n",
       "  '!',\n",
       "  \"''\",\n",
       "  '``',\n",
       "  'glad',\n",
       "  'think',\n",
       "  '.',\n",
       "  'lucky',\n",
       "  ',',\n",
       "  'poor',\n",
       "  'james',\n",
       "  'think',\n",
       "  'slighted',\n",
       "  'upon',\n",
       "  'account',\n",
       "  ';',\n",
       "  'sure',\n",
       "  'make',\n",
       "  'good',\n",
       "  'servant',\n",
       "  ':',\n",
       "  'civil',\n",
       "  ',',\n",
       "  'pretty-spoken',\n",
       "  'girl',\n",
       "  ';',\n",
       "  'great',\n",
       "  'opinion',\n",
       "  '.',\n",
       "  'whenever',\n",
       "  'see',\n",
       "  ',',\n",
       "  'always',\n",
       "  'curtseys',\n",
       "  'asks',\n",
       "  ',',\n",
       "  'pretty',\n",
       "  'manner',\n",
       "  ';',\n",
       "  'needlework',\n",
       "  ',',\n",
       "  'observe',\n",
       "  'always',\n",
       "  'turns',\n",
       "  'lock',\n",
       "  'door',\n",
       "  'right',\n",
       "  'way',\n",
       "  'never',\n",
       "  'bangs',\n",
       "  '.',\n",
       "  'sure',\n",
       "  'excellent',\n",
       "  'servant',\n",
       "  ';',\n",
       "  'great',\n",
       "  'comfort',\n",
       "  'poor',\n",
       "  'miss',\n",
       "  'taylor',\n",
       "  'somebody',\n",
       "  'used',\n",
       "  'see',\n",
       "  '.',\n",
       "  'whenever',\n",
       "  'james',\n",
       "  'goes',\n",
       "  'see',\n",
       "  'daughter',\n",
       "  ',',\n",
       "  'know',\n",
       "  ',',\n",
       "  'hearing',\n",
       "  '.',\n",
       "  'able',\n",
       "  'tell',\n",
       "  '.',\n",
       "  \"''\",\n",
       "  'emma',\n",
       "  'spared',\n",
       "  'exertions',\n",
       "  'maintain',\n",
       "  'happier',\n",
       "  'flow',\n",
       "  'ideas',\n",
       "  ',',\n",
       "  'hoped',\n",
       "  ',',\n",
       "  'help',\n",
       "  'backgammon',\n",
       "  ',',\n",
       "  'get',\n",
       "  'father',\n",
       "  'tolerably',\n",
       "  'evening',\n",
       "  ',',\n",
       "  'attacked',\n",
       "  'regrets',\n",
       "  '.',\n",
       "  'backgammon-table',\n",
       "  'placed',\n",
       "  ';',\n",
       "  'visitor',\n",
       "  'immediately',\n",
       "  'afterwards',\n",
       "  'walked',\n",
       "  'made',\n",
       "  'unnecessary',\n",
       "  '.',\n",
       "  'mr.',\n",
       "  'knightley',\n",
       "  ',',\n",
       "  'sensible',\n",
       "  'man',\n",
       "  'seven',\n",
       "  'eight-and-thirty',\n",
       "  ',',\n",
       "  'old',\n",
       "  'intimate',\n",
       "  'friend',\n",
       "  'family',\n",
       "  ',',\n",
       "  'particularly',\n",
       "  'connected',\n",
       "  ',',\n",
       "  'elder',\n",
       "  'brother',\n",
       "  'isabella',\n",
       "  'husband',\n",
       "  '.',\n",
       "  'lived',\n",
       "  'mile',\n",
       "  'highbury',\n",
       "  ',',\n",
       "  'frequent',\n",
       "  'visitor',\n",
       "  ',',\n",
       "  'always',\n",
       "  'welcome',\n",
       "  ',',\n",
       "  'time',\n",
       "  'welcome',\n",
       "  'usual',\n",
       "  ',',\n",
       "  'coming',\n",
       "  'directly',\n",
       "  'mutual',\n",
       "  'connexions',\n",
       "  ...])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original = Text(word_tokenize(corpus))\n",
    "#original = Text(word_tokenize(corpus.lower()))\n",
    "#original = Text(word_tokenize(pattern.sub(\"\", corpus.lower())))\n",
    "#original = Text(word_tokenize(pattern.sub(\" \", corpus.lower())))\n",
    "original = Text([ _ for _ in word_tokenize(pattern.sub(\" \",corpus.lower())) if _ not in stop])\n",
    "len([ _ for _ in original]), [ _ for _ in original]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013406086833811563"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(length.vocab())\n",
    "length.vocab().freq(\"emma\")  # ==> 확률정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'** ** ** 짜증나'"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#=> lexicon resource(X,돈)\n",
    "stop = [\"시발\",\"씨발\"]\n",
    "\n",
    "sentence = \"시발 시발 시발 짜증나\"\n",
    "result = list()\n",
    "\n",
    "#[ _ for _ in sentence.split() if _ not in stop]\n",
    "for _ in sentence.split() :\n",
    "    if _ not in stop :\n",
    "        result.append(_)\n",
    "    else:\n",
    "        result.append(\"*\"*len(_))\n",
    "\n",
    "\" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'** ** ** 짜증나'"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정규식\n",
    "#=> lexicon resource(X,돈)\n",
    "import re\n",
    "\n",
    "stop = [\"시발\",\"씨발\"]\n",
    "\n",
    "sentence = \"시발 시발 시발 짜증나\"\n",
    "result = list()\n",
    "\n",
    "#[ _ for _ in sentence.split() if _ not in stop]\n",
    "for _ in sentence.split() :\n",
    "    if not re.search(stop[0],_) :\n",
    "        result.append(_)\n",
    "    else:\n",
    "        result.append(\"*\"*len(_))\n",
    "\n",
    "\" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-251-c9a28e165ee7>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-251-c9a28e165ee7>\"\u001b[1;36m, line \u001b[1;32m22\u001b[0m\n\u001b[1;33m    if not re.search(stop[0], re.sub(r\"\\B[0-9{0}]+\\B\".format(re.escape(puntuation))))\u001b[0m\n\u001b[1;37m                                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 정규식\n",
    "#=> lexicon resource(X,돈)\n",
    "import re\n",
    "\n",
    "stop = [\"시발\",\"씨발\"]\n",
    "\n",
    "sentence = \"시발 시발 시발 짜증나 너ㅏ란미러ㅣㅁ2324 ㅏㄴ미러민러\"\n",
    "result = list()\n",
    "\n",
    "def umjeol(text,n=2) :\n",
    "    ngram = list()\n",
    "    \n",
    "    for i in range(len(text)-(n-1)) :\n",
    "        #print(i)\n",
    "        #print(tokens[i:i+n])\n",
    "        ngram.append(\" \".join(text[i:i+n]))\n",
    "    return ngram\n",
    "\n",
    "#[ _ for _ in sentence.split() if _ not in stop]\n",
    "for _ in sentence.split() :\n",
    "    \n",
    "    if not re.search(stop[0], re.sub(r\"\\B[0-9{0}]+\\B\".format(re.escape(puntuation))))\n",
    "    #flag = False\n",
    "    #for ngram in umjeol(_):\n",
    "    #    if ngram in stop :\n",
    "    #        flag = True\n",
    "    \n",
    "    #if not flag :\n",
    "        result.append(_)\n",
    "    else:\n",
    "        result.append(\"*\"*len(_))\n",
    "\n",
    "\" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<w>시 발</w>': 2,\n",
       " '<w>시 1 발</w>': 2,\n",
       " '<w>시 ~ 1 발</w>': 6,\n",
       " '<w>시 1 2 3 1 2 3 1 2 ~ ~ ~ 발</w>': 3}"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "# l o : 5\n",
    "# o w : 5\n",
    "# w e : 5\n",
    "def ngram(data, n=2) :\n",
    "    result = defaultdict(int)\n",
    "    for term, freq in data.items() :\n",
    "        tokens = term.split()\n",
    "        for i in range(len(tokens)-(n-1)) :\n",
    "            result[\" \".join(tokens[i:i+n])] += freq\n",
    "    return result\n",
    "import re\n",
    "\n",
    "def mergeNgram(maxKey,data) :\n",
    "    newData = dict()\n",
    "    for term, freq in data.items() :\n",
    "        newKey = re.sub(maxKey , maxKey.replace(\" \",\"\"),term)\n",
    "        newData[newKey] = freq\n",
    "    return newData\n",
    "\n",
    "\n",
    "def splitTerm(term) :\n",
    "    result = list()\n",
    "    for token in term.split():\n",
    "        result.append(\" \".join([\"<w>\"] + list(term) + [\"</w>\"]))\n",
    "    return \" _ \".join(result)\n",
    "\n",
    "data = {\n",
    "    splitTerm(\"시발\"):2,\n",
    "    splitTerm(\"시1발\"):2,\n",
    "    splitTerm(\"시~1발\"):6,\n",
    "    splitTerm(\"시12312312~~~발\"):3,\n",
    "}\n",
    "\n",
    "for _ in range(2) :\n",
    "    bigram = ngram(data)\n",
    "    maxKey = max(bigram, key=bigram.get)\n",
    "    data = mergeNgram(maxKey,data)\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'<w>시 발</w>': 2,\n",
       "             '<w>시 1': 5,\n",
       "             '1 발</w>': 8,\n",
       "             '<w>시 ~': 6,\n",
       "             '~ 1': 6,\n",
       "             '1 2': 9,\n",
       "             '2 3': 6,\n",
       "             '3 1': 6,\n",
       "             '2 ~': 3,\n",
       "             '~ ~': 6,\n",
       "             '~ 발</w>': 3})"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('발</w>', 13), ('<w>시', 13)]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = defaultdict(int)\n",
    "for _ in data :\n",
    "    for token in set(_.split()) :\n",
    "        pattern[token] += data[_]\n",
    "\n",
    "pattern = sorted(pattern.items(),key=lambda x:x[1], reverse=True)[:2]\n",
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re.compile('<w>시.*발</w>')\n",
      "*********\n",
      "*********\n",
      "***********\n",
      "<w>짜증나</w>\n",
      "<w>너ㅏ란미러ㅣㅁ2324</w>\n",
      "<w>ㅏㄴ미러민러</w>\n"
     ]
    }
   ],
   "source": [
    "## Stopwords => List(Dictionary) 힘들다\n",
    "## BPE ==> 패턴(쌍) 찾아서 적용할 수 있다\n",
    "\n",
    "sentence = \"시발 시발 시~~발 짜증나 너ㅏ란미러ㅣㅁ2324 ㅏㄴ미러민러\"\n",
    "#splitTerm(sentence)\n",
    "stopRE = re.compile(r\"{0}.*{1}\".format(pattern[1][0], pattern[0][0]))\n",
    "print(stopRE)\n",
    "for _ in [\"<w>\" + _ + \"</w>\" for _ in sentence.split()] :\n",
    "    if not stopRE.search(_) :\n",
    "        print(_)\n",
    "    else :\n",
    "        print(\"*\"*len(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "# 1. tokenizing\n",
    "# 2. 영어(lowercase)\n",
    "# 3. 구두점(in, re)\n",
    "# 4. 불용어(stopwards, [사전] in korea)\n",
    "# 5. 단어의 길이\n",
    "# 6. 단어의 빈도\n",
    "# 7. filtering = 욕설 (BPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EC': '연결 어미',\n",
       " 'ECD': '의존적 연결 어미',\n",
       " 'ECE': '대등 연결 어미',\n",
       " 'ECS': '보조적 연결 어미',\n",
       " 'EF': '종결 어미',\n",
       " 'EFA': '청유형 종결 어미',\n",
       " 'EFI': '감탄형 종결 어미',\n",
       " 'EFN': '평서형 종결 어미',\n",
       " 'EFO': '명령형 종결 어미',\n",
       " 'EFQ': '의문형 종결 어미',\n",
       " 'EFR': '존칭형 종결 어미',\n",
       " 'EP': '선어말 어미',\n",
       " 'EPH': '존칭 선어말 어미',\n",
       " 'EPP': '공손 선어말 어미',\n",
       " 'EPT': '시제 선어말 어미',\n",
       " 'ET': '전성 어미',\n",
       " 'ETD': '관형형 전성 어미',\n",
       " 'ETN': '명사형 전성 어미',\n",
       " 'IC': '감탄사',\n",
       " 'JC': '접속 조사',\n",
       " 'JK': '조사',\n",
       " 'JKC': '보격 조사',\n",
       " 'JKG': '관형격 조사',\n",
       " 'JKI': '호격 조사',\n",
       " 'JKM': '부사격 조사',\n",
       " 'JKO': '목적격 조사',\n",
       " 'JKQ': '인용격 조사',\n",
       " 'JKS': '주격 조사',\n",
       " 'JX': '보조사',\n",
       " 'MA': '부사',\n",
       " 'MAC': '접속 부사',\n",
       " 'MAG': '일반 부사',\n",
       " 'MD': '관형사',\n",
       " 'MDN': '수 관형사',\n",
       " 'MDT': '일반 관형사',\n",
       " 'NN': '명사',\n",
       " 'NNB': '일반 의존 명사',\n",
       " 'NNG': '보통명사',\n",
       " 'NNM': '단위 의존 명사',\n",
       " 'NNP': '고유명사',\n",
       " 'NP': '대명사',\n",
       " 'NR': '수사',\n",
       " 'OH': '한자',\n",
       " 'OL': '외국어',\n",
       " 'ON': '숫자',\n",
       " 'SE': '줄임표',\n",
       " 'SF': '마침표, 물음표, 느낌표',\n",
       " 'SO': '붙임표(물결,숨김,빠짐)',\n",
       " 'SP': '쉼표,가운뎃점,콜론,빗금',\n",
       " 'SS': '따옴표,괄호표,줄표',\n",
       " 'SW': '기타기호 (논리수학기호,화폐기호)',\n",
       " 'UN': '명사추정범주',\n",
       " 'VA': '형용사',\n",
       " 'VC': '지정사',\n",
       " 'VCN': \"부정 지정사, 형용사 '아니다'\",\n",
       " 'VCP': \"긍정 지정사, 서술격 조사 '이다'\",\n",
       " 'VV': '동사',\n",
       " 'VX': '보조 용언',\n",
       " 'VXA': '보조 형용사',\n",
       " 'VXV': '보조 동사',\n",
       " 'XP': '접두사',\n",
       " 'XPN': '체언 접두사',\n",
       " 'XPV': '용언 접두사',\n",
       " 'XR': '어근',\n",
       " 'XSA': '형용사 파생 접미사',\n",
       " 'XSN': '명사파생 접미사',\n",
       " 'XSV': '동사 파생 접미사'}"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Kkma\n",
    "\n",
    "Kkma().tagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CD: numeral, cardinal\n",
      "    two one 1 four 2 1913 71 74 637 1937 8 five three million 87-31 29-5\n",
      "    seven 1,119 fifty-three 7.5 billion hundred 125,000 1,700 60 100 six\n",
      "    ...\n"
     ]
    }
   ],
   "source": [
    "from nltk.help import brown_tagset\n",
    "#brown_tagset()\n",
    "#brown_tagset(\"N\")\n",
    "brown_tagset(\"CD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[', 'NNP'),\n",
       " ('Emma', 'NNP'),\n",
       " ('by', 'IN'),\n",
       " ('Jane', 'NNP'),\n",
       " ('Austen', 'NNP'),\n",
       " ('1816', 'CD'),\n",
       " (']', 'NNP'),\n",
       " ('VOLUME', 'NNP'),\n",
       " ('I', 'NNP'),\n",
       " ('CHAPTER', 'NNP'),\n",
       " ('I', 'NNP'),\n",
       " ('Emma', 'NNP'),\n",
       " ('Woodhouse', 'NNP'),\n",
       " (',', ','),\n",
       " ('handsome', 'JJ'),\n",
       " (',', ','),\n",
       " ('clever', 'JJ'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('rich', 'JJ'),\n",
       " (',', ','),\n",
       " ('with', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('comfortable', 'JJ'),\n",
       " ('home', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('happy', 'JJ'),\n",
       " ('disposition', 'NN'),\n",
       " (',', ','),\n",
       " ('seemed', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('unite', 'VB'),\n",
       " ('some', 'DT'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('best', 'JJS'),\n",
       " ('blessings', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('existence', 'NN'),\n",
       " (';', ':'),\n",
       " ('and', 'CC'),\n",
       " ('had', 'VBD'),\n",
       " ('lived', 'VBN'),\n",
       " ('nearly', 'RB'),\n",
       " ('twenty-one', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('very', 'RB'),\n",
       " ('little', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('distress', 'NN'),\n",
       " ('or', 'CC'),\n",
       " ('vex', 'VB'),\n",
       " ('her', 'PRP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "#StanfordTagger()\n",
    "\n",
    "MODEL =  \"C:\\\\Users\\\\USER\\\\Downloads\\\\KONLPY\\\\NER\\\\stanford-postagger-full-2018-10-16\\\\stanford-postagger-full-2018-10-16\\\\models\\\\english-bidirectional-distsim.tagger\"\n",
    "PARSER = \"C:\\\\Users\\\\USER\\\\Downloads\\\\KONLPY\\\\NER\\\\stanford-postagger-full-2018-10-16\\\\stanford-postagger-full-2018-10-16\\\\stanford-postagger-3.9.2.jar\"\n",
    "pos = StanfordPOSTagger(MODEL,PARSER) \n",
    "\n",
    "pos.tag(word_tokenize(sent_tokenize(corpus)[0]))\n",
    "#pos.tag_sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
